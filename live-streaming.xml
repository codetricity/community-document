<?xml version="1.0" encoding="UTF-8"?>
<?asciidoc-toc maxdepth="2"?>
<?asciidoc-numbered?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:xl="http://www.w3.org/1999/xlink" version="5.0" xml:lang="en">
<info>
<title>RICOH THETA Live Streaming</title>
<date>2016-10-18</date>
</info>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-73311422-1', 'auto');
ga('send', 'pageview');
ga('set', 'contentGroup1', 'All RICOH');
</script>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/doc-banner.png"/>
</imageobject>
<textobject><phrase>doc banner</phrase></textobject>
</mediaobject>
</informalfigure>
<section xml:id="_enable_live_streaming_mode">
<title>Enable Live Streaming Mode</title>
<simpara>With the THETA off, press and hold the <emphasis>mode</emphasis> button. Keep pressing mode
and then press <emphasis>power</emphasis>. The camera will go into live streaming mode.</simpara>
<figure role="thumb">
<title>Start THETA in LiveStreaming mode</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mode-buttons.png"/>
</imageobject>
<textobject><phrase>mode buttons</phrase></textobject>
</mediaobject>
</figure>
<simpara>With the camera in live streaming mode, the word <emphasis>Live</emphasis> will appear in blue.</simpara>
<figure role="thumb">
<title>Verify that the camera&#8217;s <emphasis>Live</emphasis> light is on</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/live-light.png"/>
</imageobject>
<textobject><phrase>live light</phrase></textobject>
</mediaobject>
</figure>
</section>
<section xml:id="_connect_camera_to_computer">
<title>Connect Camera to Computer</title>
<simpara>Plug the camera into your computer with a micro USB cable. It will appear as a normal
webcam. The camera will be called <emphasis>RICOH THETA S</emphasis>.</simpara>
<figure role="thumb">
<title>Confirm you can see <emphasis>RICOH THETA S</emphasis> as a webcam</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/skype-webcam.png"/>
</imageobject>
<textobject><phrase>skype webcam</phrase></textobject>
</mediaobject>
</figure>
<simpara>The THETA is now streaming in dual-fisheye mode. The stream is 1280x720 at 15fps.
The data is in MotionJPEG format.</simpara>
</section>
<section xml:id="_install_live_streaming_software">
<title>Install Live Streaming Software</title>
<simpara>To stream the video to YouTube, install the official
<link xl:href="https://theta360.com/en/support/download/">RICOH Live-streaming app</link> and
<link xl:href="https://obsproject.com/">OBS</link>.</simpara>
<note>
<simpara>Many software can be used to stream to YouTube. Refer to
<link xl:href="https://support.google.com/youtube/answer/2907883?hl=en">YouTube Live Verified Devices and Software</link>
for more information.</simpara>
</note>
<section xml:id="_download_and_install_ricoh_live_streaming_app">
<title>Download and Install RICOH Live-Streaming App</title>
<simpara><link xl:href="https://theta360.com/en/support/download/">Download</link></simpara>
<figure role="thumb">
<title>Download the RICOH Live-Streaming App</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/live-streaming-download.png"/>
</imageobject>
<textobject><phrase>live streaming download</phrase></textobject>
</mediaobject>
</figure>
<orderedlist numeration="arabic">
<listitem>
<simpara>Select Windows 32bit, Windows 64bit, or Mac</simpara>
</listitem>
<listitem>
<simpara>Turn your THETA off</simpara>
</listitem>
<listitem>
<simpara>Unplug THETA from your computer</simpara>
</listitem>
<listitem>
<simpara>Install software</simpara>
</listitem>
</orderedlist>
<figure role="thumb">
<title>Live-Streaming App File is Called UVC Blender</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/uvcblender-install.png"/>
</imageobject>
<textobject><phrase>uvcblender install</phrase></textobject>
</mediaobject>
</figure>
<simpara>With the THETA turned off, the software will prompt you to reconnect the THETA to register your camera.</simpara>
<figure role="thumb">
<title>Register THETA with computer</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/register.png"/>
</imageobject>
<textobject><phrase>register</phrase></textobject>
</mediaobject>
</figure>
<simpara>After you connect your THETA, a <emphasis>Register</emphasis> button will appear.</simpara>
<figure role="thumb">
<title>Register buttons appears after connection</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/register-button.png"/>
</imageobject>
<textobject><phrase>register button</phrase></textobject>
</mediaobject>
</figure>
<simpara>Complete the registration.</simpara>
<figure role="thumb">
<title>Camera and computer registration complete</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/registration-complete.png"/>
</imageobject>
<textobject><phrase>registration complete</phrase></textobject>
</mediaobject>
</figure>
<simpara>Test the THETA UVC Blender driver with any software that works with a webcam. In the example
below, I am using Skype.</simpara>
<figure role="thumb">
<title>Testing THETA UVC Blender with Skype</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/theta-uvc-skype-select.png"/>
</imageobject>
<textobject><phrase>theta uvc skype select</phrase></textobject>
</mediaobject>
</figure>
<caution>
<simpara>Make sure you select <emphasis>THETA UVC Blender</emphasis> and not <emphasis>RICOH THETA S</emphasis>.</simpara>
</caution>
<note>
<simpara>In Skype, the video does not have 360&#176; navigation (as of Oct 2016) and it will
look like a distorted rectangle. Skype is for testing only, not for use.</simpara>
</note>
</section>
<section xml:id="_download_and_install_obs">
<title>Download and Install OBS</title>
<figure role="thumb">
<title>OBS Studio</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-icon.png"/>
</imageobject>
<textobject><phrase>obs icon</phrase></textobject>
</mediaobject>
</figure>
<simpara><link xl:href="https://obsproject.com/">Download OBS</link></simpara>
<simpara>Create a new <emphasis>Scene</emphasis>. Any name is fine. Click on the plus sign. Under
<emphasis>Sources</emphasis>, add THETA UVC Blender (any name is fine) and add
a video capture device. Right click to open the pop-up menu.</simpara>
<figure role="thumb">
<title>Add Video Capture Device to OBS <emphasis>Sources</emphasis></title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-video-capture.png"/>
</imageobject>
<textobject><phrase>obs video capture</phrase></textobject>
</mediaobject>
</figure>
<simpara>Select <emphasis>THETA UVC Blender</emphasis> as the Device. Verify that the video stream is in equirectangular format.</simpara>
<figure role="thumb">
<title>Verify THETA UVC Blender works in OBS</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-device.png"/>
</imageobject>
<textobject><phrase>obs device</phrase></textobject>
</mediaobject>
</figure>
<tip>
<simpara>If you see a black screen that says <emphasis>Status:0x800705AA</emphasis>, try to toggle your device between your two
webcams. If you still see the error, disconnect all other webcams or disable the webcam on your laptop
and then reboot your computer. The error above indicates that a connection is not established. See Troubleshooting
section below</simpara>
</tip>
<simpara>Leave the Resolution/FPS Type as <emphasis>Device Default</emphasis>.</simpara>
<figure role="thumb">
<title>Leave Resolution/FPS Type as Default</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/resolution-fps.png"/>
</imageobject>
<textobject><phrase>resolution fps</phrase></textobject>
</mediaobject>
</figure>
<simpara>Under Settings &#8594; Video, set the resolution to 1280x720.</simpara>
<figure role="thumb">
<title>Configure Resolution to 1280x720</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-settings-video.png"/>
</imageobject>
<textobject><phrase>obs settings video</phrase></textobject>
</mediaobject>
</figure>
<note>
<simpara>As of Oct 2016, the maximum resolution for UVC Blender is 720p. It&#8217;s likely that a higher resolution
driver may be available in the future. Please check the maximum resolution and adjust your settings if needed.</simpara>
</note>
<simpara>Select Stretch to screen.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-stretch-to-screen.png"/>
</imageobject>
<textobject><phrase>obs stretch to screen</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
</section>
<section xml:id="_create_a_youtube_live_360_event">
<title>Create a YouTube Live 360&#176; Event</title>
<simpara>Log into YouTube. Click on the <emphasis>Upload</emphasis> button.
Click the <emphasis>Get started</emphasis> button on live streaming.</simpara>
<figure role="thumb">
<title>Click Live Streaming after you click upload</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-livestream.png"/>
</imageobject>
<textobject><phrase>youtube livestream</phrase></textobject>
</mediaobject>
</figure>
<simpara>Select <emphasis>Events</emphasis>.</simpara>
<figure role="thumb">
<title>Select Events</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-event.png"/>
</imageobject>
<textobject><phrase>youtube event</phrase></textobject>
</mediaobject>
</figure>
<warning>
<simpara>Make sure you select Events. You will not get a 360&#176; stream with <emphasis>Stream now</emphasis>.</simpara>
</warning>
<simpara>In the right side of the screen, select <emphasis>New live event</emphasis>.</simpara>
<figure role="thumb">
<title>New live event</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-new-live-event.png"/>
</imageobject>
<textobject><phrase>youtube new live event</phrase></textobject>
</mediaobject>
</figure>
<simpara>Add a title.</simpara>
<simpara>Select Advanced Settings</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-advanced-settings.png"/>
</imageobject>
<textobject><phrase>youtube advanced settings</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Select <emphasis>This live stream is 360</emphasis>.</simpara>
<figure role="thumb">
<title>Select <emphasis>This live stream is 360</emphasis></title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-livestream360.png"/>
</imageobject>
<textobject><phrase>youtube livestream360</phrase></textobject>
</mediaobject>
</figure>
<simpara>Grab stream name from <emphasis>Ingestion Settings</emphasis></simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-ingestion-1.png"/>
</imageobject>
<textobject><phrase>youtube ingestion 1</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Once you click on <emphasis>Basic ingestion</emphasis> information on your encoder will open up.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-basic-ingestion.png"/>
</imageobject>
<textobject><phrase>youtube basic ingestion</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Copy the stream name. You will need this for OBS. In OBS, it is called, <emphasis>Stream key</emphasis>.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-streamname.png"/>
</imageobject>
<textobject><phrase>youtube streamname</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Open OBS, go to Settings &#8594; Stream. Paste the YouTube stream name into the box
on OBS called, <emphasis>Stream key</emphasis>.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-streamkey.png"/>
</imageobject>
<textobject><phrase>obs streamkey</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>On the main OBS front control panel, press <emphasis>Start Streaming</emphasis> in the right hand
side of the control panel.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-start-streaming.png"/>
</imageobject>
<textobject><phrase>obs start streaming</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>On YouTube, go to the <emphasis>Live Control Room</emphasis> and click <emphasis>Preview Stream</emphasis>.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-preview.png"/>
</imageobject>
<textobject><phrase>youtube preview</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>You can preview the stream if you have good bandwidth. I have limited
upstream bandwidth in my office. I reduced the ingestion bandwidth,
making my resolution lower.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-preview-test.png"/>
</imageobject>
<textobject><phrase>youtube preview test</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>When you&#8217;re ready, start the stream.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/youtube-streaming.png"/>
</imageobject>
<textobject><phrase>youtube streaming</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
<section xml:id="_using_hdmi">
<title>Using HDMI</title>
<simpara>Using USB output for live streaming, you will get a maximum resolution of 720p.
If you save your video files to your camera, the resolution will be 1920x1080.
If you save still images as timelapse, you can get 5376x2688, which will be displayed
as 4K on YouTube.</simpara>
<simpara>The THETA S has an HDMI port that can output 1920x1080 at 30fps. In order to use
this signal, you need to use something like
<link xl:href="https://www.blackmagicdesign.com/products/ultrastudiothunderbolt">Blackmagicdesign UltraStudio for Thunderbolt</link>.</simpara>
<simpara>Once you get the video stream onto your computer, it will be in dual-fisheye.
To get this into equirectangular, you will need to use a third-party product
such as
<link xl:href="http://theta360.guide/showcase/ricoh-product-streambox.html">Streambox Cloud Encoder</link> or
MimoLive.</simpara>
<section xml:id="_streambox">
<title>Streambox</title>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/streambox-theta.png"/>
</imageobject>
<textobject><phrase>streambox theta</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>This is the workflow.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/streambox-workflow.png"/>
</imageobject>
<textobject><phrase>streambox workflow</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>This is a
<link xl:href="https://www.youtube.com/watch?v=d8TN_Vc6wL0">sample of the live stream using a THETA</link>.</simpara>
<informalfigure role="thumb">
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/streambox-sample.png"/>
</imageobject>
<textobject><phrase>streambox sample</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>This is the equipment and service list used:</simpara>
<itemizedlist>
<listitem>
<simpara>Streamed live using Streambox Cloud Encoder</simpara>
</listitem>
<listitem>
<simpara>RICOH THETA S Camera</simpara>
</listitem>
<listitem>
<simpara>BlackMagic UltraStudio Mini Recorder</simpara>
</listitem>
<listitem>
<simpara>MacBook Pro with USB Modems</simpara>
</listitem>
<listitem>
<simpara>Streambox Cloud</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="_mimolive">
<title>mimoLive</title>
<simpara>Boinx Software offers <link xl:href="https://boinx.com/mimolive/">mimoLive</link>.</simpara>
<simpara>They have a good video that provides an <link xl:href="https://youtu.be/nNQES53S2jc">overview of their service</link>
specifically for the THETA S.</simpara>
<simpara>mimoLive can accept a USB or HDMI stream in dual-fisheye.</simpara>
<simpara>In order to use the HDMI output from the THETA, you will need a HDMI video grabber.
Boinx Software recommends the Blackmagic Design
<link xl:href="https://www.blackmagicdesign.com/products/ultrastudiothunderbolt">UltraStudio</link> Mini Recorder for Thunderbolt or the
<link xl:href="http://www.magewell.com/usb-capture-hdmi">Magewell USB Capture HDMI adapter for USB 3</link>.</simpara>
<figure role="thumb">
<title>Getting THETA S HDMI Output Into Your Computer</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/hdmi-usb.png"/>
</imageobject>
<textobject><phrase>hdmi usb</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>mimoLive dual-fisheye before conversion to equirectangular</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/dual-fisheye.png"/>
</imageobject>
<textobject><phrase>dual fisheye</phrase></textobject>
</mediaobject>
</figure>
<simpara>mimoLive can take the THETA S dual-fisheye video stream source and apply a filter convert it to equirectangular for
streaming to places like YouTube Live 360 events.</simpara>
<figure role="thumb">
<title>Preset configuration and filter for THETA S</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/sources-thetas.png"/>
</imageobject>
<textobject><phrase>sources thetas</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>Filter converts dual-fisheye stream to equirectangular</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/placerlive.png"/>
</imageobject>
<textobject><phrase>placerlive</phrase></textobject>
</mediaobject>
</figure>
<simpara>mimoLive provides sliders to adjust the sphere stitching. You&#8217;ll only be able to get a <emphasis>good enough</emphasis> stitch. The
edges of the spheres will not match perfectly.</simpara>
<figure role="thumb">
<title>Use sliders to adjust sphere edges</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/adjustment.png"/>
</imageobject>
<textobject><phrase>adjustment</phrase></textobject>
</mediaobject>
</figure>
<simpara>This is an example of the <link xl:href="https://youtu.be/8CEB2_YQgkU">360 live stream</link>. The quality of the stitch
is good.</simpara>
<simpara>Even if you are using USB output, you still may want to use mimoLive instead of the free RICOH THETA
UVC Blender app to take advantage of mimoLive features to add text, Twitter, and slides into the
YouTube live streaming event.</simpara>
<figure role="thumb">
<title>Place text into live stream to YouTube</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/text-placement360.png"/>
</imageobject>
<textobject><phrase>text placement360</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>Insert Twitter into live stream to YouTube</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/twitter.png"/>
</imageobject>
<textobject><phrase>twitter</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>Insert presentation slides into 360 live stream</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/slides.png"/>
</imageobject>
<textobject><phrase>slides</phrase></textobject>
</mediaobject>
</figure>
<simpara>You can also center your video stream.</simpara>
<figure role="thumb">
<title>Center 360 live stream</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mimolive/adjust-center.png"/>
</imageobject>
<textobject><phrase>adjust center</phrase></textobject>
</mediaobject>
</figure>
<simpara><link xl:href="https://youtu.be/8CEB2_YQgkU">Example Stream Archive</link></simpara>
</section>
<section xml:id="_other">
<title>Other</title>
<simpara><link xl:href="http://shop.videostream360.com/vr-cams-equipment/360camera">Videostream360</link>
offers a service to use THETA at 1920x1080 with HDMI. They even sell the THETA on their site.</simpara>
<simpara>If you have a solution for HDMI 360&#176; streaming and you&#8217;ve verified that it
works with the THETA, please join the
<link xl:href="http://theta360.guide/ecosystem/">THETA Ecosystem</link> and
<link xl:href="http://lists.theta360.guide/c/theta-media/ecosystem-discussion">post</link>
information about it.</simpara>
</section>
</section>
<section xml:id="_tethered_streaming_with_unity">
<title>Tethered Streaming with Unity</title>
<simpara>Please refer to this
<link xl:href="http://lists.theta360.guide/t/using-ricoh-theta-live-view-with-unity/70?u=codetricity">separate article</link>
on using Unity with a tethered THETA.</simpara>
</section>
<section xml:id="_untethered_wifi_streaming">
<title>Untethered WiFi Streaming</title>
<simpara>Streaming from the THETA using WiFi is primarily of interest to developers
and hobbyists.</simpara>
<section xml:id="_using_unity">
<title>Using Unity</title>
<simpara>The THETA can live stream a 640x320 MotionJPEG at 10fps over WiFi.
This is intended to preview
a picture prior to taking the picture. It&#8217;s not intended for headset navigation.
The community has built some solutions to stream this low-res, low fps video
to mobile phones, primarily using Unity.</simpara>
<simpara>This is a short Vine video of a
<link xl:href="https://vine.co/v/eV9XDQBEujt">demo</link>.</simpara>
<figure role="thumb">
<title>360&#176; video stream using WiFi</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/wifi-unity.png"/>
</imageobject>
<textobject><phrase>wifi unity</phrase></textobject>
</mediaobject>
</figure>
<simpara>Most developers have challenges processing the MotionJPEG stream.</simpara>
<simpara>Fortunately,
<link xl:href="https://github.com/theta360developers/ThetaWifiStreaming">sample code</link>
 of a THETA S WiFi streaming demo with Unity was developed by community member
<link xl:href="https://github.com/makoto-unity">Makoto Ito</link>.
 I&#8217;ve translated the
 <link xl:href="https://github.com/makoto-unity/ThetaWifiStreaming/blob/master/README.md">README</link>
to his code as well as a
<link xl:href="http://noshipu.hateblo.jp/entry/2016/04/21/183439">related blog</link> written by
<link xl:href="https://twitter.com/noshipu">@noshipu</link>, CEO of
<link xl:href="http://vird.co.jp/">ViRD, Inc</link> for his contribution.</simpara>
<section xml:id="_about_the_ricoh_theta_api">
<title>About the RICOH THETA API</title>
<simpara>In order to use Wifi live streaming, you must use the <literal>_getLivePreview</literal> API.
<link xl:href="https://developers.theta360.com/en/docs/v2.0/api_reference/commands/camera._get_live_preview.html">Official Reference</link></simpara>
<blockquote>
<simpara>NOTE from Craig: This was replaced by
<link xl:href="https://developers.theta360.com/en/docs/v2.1/api_reference/commands/camera.get_live_preview.html">getLivePreview</link>
in version 2.1 of the API. This blog by Noshipu-san refers to the 2.0 API, which is still supported by
the THETA S. Be aware of the differences in your code.</simpara>
</blockquote>
<simpara>Unlike the other APIs, <literal>_getLivePreview</literal> is different because the data is in a stream and keeps going. You will not be able to get a WWW class to wait until the request is complete (maybe).</simpara>
<blockquote>
<simpara>NOTE from Craig: This is the major problem developers have when working with <literal>getLivePreview</literal>. As the data
is a stream, you can&#8217;t want for the data to end before running your next command. For example, it&#8217;s
different from downloading and displaying an image or video file because you know when the transfer is
complete.</simpara>
</blockquote>
</section>
<section xml:id="_processing_flow">
<title>Processing Flow</title>
<section xml:id="_set_the_post_request_to_create_a_httpwebrequest_class">
<title>Set the POST request to create a HttpWebRequest class</title>
<literallayout class="monospaced">string url = "Enter HTTP path of THETA here";
var request = HttpWebRequest.Create (url);
HttpWebResponse response = null;
request.Method = "POST";
request.Timeout = (int) (30 * 10000f); // to ensure  no timeout
request.ContentType = "application/json; charset = utf-8";</literallayout>
<literallayout class="monospaced">byte [] postBytes = Encoding.Default.GetBytes ( "Put the JSON data here");
request.ContentLength = postBytes.Length;</literallayout>
</section>
<section xml:id="_generate_a_class_of_binaryreader_to_get_the_byte_data_you_get_the_bytes_one_by_one">
<title>Generate a class of BinaryReader to get the byte data (you get the bytes one by one)</title>
<literallayout class="monospaced">// The start of transmission of the post data
Stream reqStream = request.GetRequestStream ();
reqStream.Write (postBytes, 0, postBytes.Length) ;
reqStream.Close ();
stream = request.GetResponse () .GetResponseStream ();</literallayout>
<literallayout class="monospaced">BinaryReader reader = new BinaryReader (new BufferedStream (stream), new System.Text.ASCIIEncoding ());</literallayout>
</section>
<section xml:id="_get_the_start_and_stop_bytes_of_1_frame_of_the_motionjpeg_and_cut_out_one_frame">
<title>Get the start and stop bytes of 1 frame of the MotionJPEG and cut out one frame</title>
<simpara>With the byte, check the partion value of the MotionJPEG.</simpara>
<literallayout class="monospaced">...(http)
0xFF 0xD8      --|
[jpeg data]      |--1 frame of MotionJPEG
0xFF 0xD9      --|
...(http)
0xFF 0xD8      --|
[jpeg data]      |--1 frame of MotionJPEG
0xFF 0xD9      --|
...(http)</literallayout>
<simpara>Please refer this answer on StackOverflow to
<link xl:href="http://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera">How to Parse MJPEG HTTP stream from IP camera?</link></simpara>
<simpara>The starting 2 bytes are <literal>0xFF, 0xD8</literal>. The end bye is <literal>0xD9</literal></simpara>
<simpara>The code is shown below.</simpara>
<literallayout class="monospaced">List&lt;byte&gt; imageBytes = new List&lt;byte&gt; ();
bool isLoadStart = false; // Binary flag taken at head of image
byte oldByte = 0; // Stores one previous byte of data
while( true ) {
    byte byteData = reader.ReadByte ();</literallayout>
<literallayout class="monospaced">if (!isLoadStart) {
    if (oldByte == 0xFF){
        // First binary image
       imageBytes.Add(0xFF);
    }
    if (byteData == 0xD8){
       // Second binary image
       imageBytes.Add(0xD8);</literallayout>
<literallayout class="monospaced">       // I took the head of the image up to the end binary
       isLoadStart = true;
    }
} else {
    // Put the image binaries into an array
    imageBytes.Add(byteData);</literallayout>
<literallayout class="monospaced">        // if the byte was the end byte
        // 0xFF -&gt; 0xD9 case、end byte
        if(oldByte == 0xFF &amp;&amp; byteData == 0xD9){
            // As this is the end byte
            // we'll generate the image from the data and can create the texture
            // imageBytes are used to reflect the texture
            // imageBytes are left empty
            // the loop returns the binary image head
            isLoadStart = false;
        }
    }
    oldByte = byteData;
}</literallayout>
</section>
<section xml:id="_texture_generation_separated_by_byte">
<title>Texture Generation Separated by Byte</title>
<simpara>This is the byte to reflect the texture.</simpara>
<literallayout class="monospaced">mainTexture.LoadImage ((byte[])imageBytes.ToArray ());</literallayout>
<simpara><?asciidoc-hr?></simpara>
<simpara>Portion of Python code taken from
<link xl:href="http://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera">StackOverflow answer</link>.</simpara>
<literallayout class="monospaced">import cv2
import urllib
import numpy as np</literallayout>
<literallayout class="monospaced">    stream=urllib.urlopen('http://localhost:8080/frame.mjpg')
    bytes=''
    while True:
        bytes+=stream.read(1024)
        a = bytes.find('\xff\xd8')
        b = bytes.find('\xff\xd9')
        if a!=-1 and b!=-1:
            jpg = bytes[a:b+2]
            bytes= bytes[b+2:]
            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8),cv2.CV_LOAD_IMAGE_COLOR)
            cv2.imshow('i',i)
            if cv2.waitKey(1) ==27:
                exit(0)
Mjpeg over http is multipart/x-mixed-replace with boundary frame info and jpeg data is just sent in binary. So you don't really need to care about http protocol headers. All jpeg frames start with marker 0xff 0xd8 and end with 0xff 0xd9. So the code above extracts such frames from the http stream and decodes them one by one. like below.</literallayout>
<literallayout class="monospaced">...(http)
0xff 0xd8      --|
[jpeg data]      |--this part is extracted and decoded
0xff 0xd9      --|
...(http)
0xff 0xd8      --|
[jpeg data]      |--this part is extracted and decoded
0xff 0xd9      --|
...(http)</literallayout>
</section>
<section xml:id="_testing_wifi_streaming">
<title>Testing WiFi Streaming</title>
<simpara>You can test out WiFi Streaming without having to program.
Download and install
<link xl:href="https://store.unity.com/products/unity-personal">Unity Personal Edition</link>. It&#8217;s free.</simpara>
<simpara>Get Makoto Ito&#8217;s code for
<link xl:href="https://github.com/theta360developers/ThetaWifiStreaming">ThetaWifiStreaming</link>.</simpara>
<simpara>Press <emphasis>Play</emphasis>.</simpara>
<figure role="thumb">
<title>Unity WiFi Live Stream in Game Mode</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/unity/wifi/game-view-crop.png"/>
</imageobject>
<textobject><phrase>game view crop</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>Unity Scene View of WiFi Live Stream</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/unity/wifi/scene-4-crop.png"/>
</imageobject>
<textobject><phrase>scene 4 crop</phrase></textobject>
</mediaobject>
</figure>
<figure role="thumb">
<title>Top down view of sphere with THETA camera positions</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/unity/wifi/top-down-sphere.png"/>
</imageobject>
<textobject><phrase>top down sphere</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
</section>
<section xml:id="_using_a_raspberry_pi">
<title>Using a Raspberry Pi</title>
<simpara>A Raspberry Pi can take the video live stream from the THETA using USB
and transmit the stream to another device using WiFi. This is intended
for software developers to use as starting point.</simpara>
<simpara>There is
<link xl:href="https://github.com/theta360developers/video-streaming-sample-app">sample code</link>
 available for both the transmission of the live stream
and the conversion of the live stream into a navigable 360 video. Both the
browser and the server applications are written in JavaScript. The server application
uses node.</simpara>
<figure role="thumb">
<title>video stream prior to conversion</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/thetaview-fisheye.png"/>
</imageobject>
<textobject><phrase>thetaview fisheye</phrase></textobject>
</mediaobject>
</figure>
<simpara>The sample code uses JavaScript to convert the dual-fisheye video stream into
a navigable 360&#176; video. Transmission uses
<link xl:href="https://webrtc.org/">WebRTC</link>.</simpara>
<figure role="thumb">
<title>stream conversion done in browser</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/thetaview-360view.png"/>
</imageobject>
<textobject><phrase>thetaview 360view</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section xml:id="_faq">
<title>FAQ</title>
<simpara><emphasis role="strong">Q: What&#8217;s the Resolution and FPS?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> Updated Oct 2016.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Table THETA S Live Streaming</title>
<tgroup cols="6">
<colspec colname="col_1" colwidth="16.6666*"/>
<colspec colname="col_2" colwidth="16.6666*"/>
<colspec colname="col_3" colwidth="16.6666*"/>
<colspec colname="col_4" colwidth="16.6666*"/>
<colspec colname="col_5" colwidth="16.6666*"/>
<colspec colname="col_6" colwidth="16.667*"/>
<thead>
<row>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Format</entry>
<entry align="left" valign="top">Camera Mode</entry>
<entry align="left" valign="top">Size</entry>
<entry align="left" valign="top">Frame Rate</entry>
<entry align="left" valign="top">Connection</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Live View</simpara></entry>
<entry align="left" valign="top"><simpara>Equirectangular in MotionJPEG</simpara></entry>
<entry align="left" valign="top"><simpara>Image Only</simpara></entry>
<entry align="left" valign="top"><simpara>640x320</simpara></entry>
<entry align="left" valign="top"><simpara>10fps</simpara></entry>
<entry align="left" valign="top"><simpara>WiFi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>USB Live Streaming of dual-fisheye</simpara></entry>
<entry align="left" valign="top"><simpara>Dual-fisheye in MotionJPEG</simpara></entry>
<entry align="left" valign="top"><simpara>live streaming</simpara></entry>
<entry align="left" valign="top"><simpara>1280x720</simpara></entry>
<entry align="left" valign="top"><simpara>15fps</simpara></entry>
<entry align="left" valign="top"><simpara>USB isochronous transfer</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>HDMI live streaming of dual-fisheye</simpara></entry>
<entry align="left" valign="top"><simpara>Dual-fisheye in uncompressed YCbCr</simpara></entry>
<entry align="left" valign="top"><simpara>live streaming</simpara></entry>
<entry align="left" valign="top"><simpara>1920x1080, 1280x720, 720x480</simpara></entry>
<entry align="left" valign="top"><simpara>30fps</simpara></entry>
<entry align="left" valign="top"><simpara>HDMI</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>USB live streaming of equirectangular</simpara></entry>
<entry align="left" valign="top"><simpara>Equirectangular in MotionJPEG</simpara></entry>
<entry align="left" valign="top"><simpara>live streaming</simpara></entry>
<entry align="left" valign="top"><simpara>1280x720</simpara></entry>
<entry align="left" valign="top"><simpara>15fps</simpara></entry>
<entry align="left" valign="top"><simpara>USB</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara><?asciidoc-hr?></simpara>
<simpara><emphasis role="strong">Q: Can I stream from a drone to a headset?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> Only with expensive equipment. This is not a good use of the THETA for
recreational hobbyists.
<link xl:href="http://lists.theta360.guide/t/using-theta-360-video-from-a-drone/133?u=codetricity">Refer to this article</link> for more
information.</simpara>
<simpara><?asciidoc-hr?></simpara>
<simpara><emphasis role="strong">Q: Does the THETA have auto-stabilization?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> No. You&#8217;ll need to use a third-party
<link xl:href="http://lists.theta360.guide/t/theta-s-dokumentation-on-a-clasic-mc-rally/211/11?u=codetricity">gimbal</link>.</simpara>
<simpara><?asciidoc-hr?></simpara>
<simpara><emphasis role="strong">Q: Is anyone using the THETA 360&#176; stream for object recognition?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> Yes. Most people use the raw video from 2 fisheye spheres. Most people do not convert
to equirectangular video. Just extract a portion of the sphere and perform the
image recognition or measurement on that section. The HDMI stream has higher resolution. Most
people are using that and extracting a frame, then performing the calculation. Known applications
include facial recognition, audience emotion recognition, autonomous vehicle operation.
As just one example, the winner of the RICOH prize at the 2016 DeveloperWeek Hackathon used
the
<link xl:href="https://www.microsoft.com/cognitive-services/en-us/emotion-api">Microsoft Emotion API</link> on
the dual-fisheye spheres.</simpara>
<simpara><?asciidoc-hr?></simpara>
<simpara><emphasis role="strong">Q: Is anyone working on panoramic sound?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> Yes. There are many projects for 3D sound, including
<link xl:href="http://lists.theta360.guide/t/panoramic-videos-with-panoramic-sounds/304?u=codetricity">SOPA</link>,
an open source JavaScript library.</simpara>
<simpara><?asciidoc-hr?></simpara>
<simpara><emphasis role="strong">Q: How do I increase the sound quality?</emphasis></simpara>
<simpara><emphasis role="strong">A:</emphasis> Use an external microphone and add it to your mixer. Set the THETA&#8217;s input
to zero using your mixer. If you&#8217;re using OBS for the stream, plug your microphones into your
computer and then add a new audio source from the main dashboard to your stream.
There is no way to plug a microphone directly into the THETA.</simpara>
<figure role="thumb">
<title>OBS mixer</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/mixer.png"/>
</imageobject>
<textobject><phrase>mixer</phrase></textobject>
</mediaobject>
</figure>
</section>
<section xml:id="_troubleshooting">
<title>Troubleshooting</title>
<section xml:id="_streaming_to_youtube">
<title>Streaming to YouTube</title>
<section xml:id="_problem_status_0x800705aa">
<title>Problem: Status:0x800705AA</title>
<figure role="thumb">
<title>Error message when device not detected</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/obs-error.png"/>
</imageobject>
<textobject><phrase>obs error</phrase></textobject>
</mediaobject>
</figure>
<orderedlist numeration="arabic">
<listitem>
<simpara>Verify your firmware is 01.42 or above</simpara>
</listitem>
<listitem>
<simpara>Make sure your camera has the blue word <literal>Live</literal> in LED lights on</simpara>
</listitem>
<listitem>
<simpara>Toggle between webcam and UV Blender. If this still fails to resolve the problem,
disable all other webcams and reboot</simpara>
</listitem>
<listitem>
<simpara>Try a different USB cable. Plug it into the port on the back of your computer</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_problem_screen_is_black_with_nothing_on_it">
<title>Problem: Screen is black with nothing on it</title>
<simpara>Check video resolution. Set to 1280x720</simpara>
</section>
<section xml:id="_problem_video_on_youtube_is_equirectangular_with_no_navigation">
<title>Problem: Video on YouTube is Equirectangular with No Navigation</title>
<simpara>If the stream is in equirectangular on OBS and it can&#8217;t be navigated on YouTube, check
your YouTube configuration.</simpara>
</section>
</section>
<section xml:id="_heat">
<title>Heat</title>
<simpara>The unit below overheated 16 minutes into the shoot. It is using UVC Blender and a
USB cable during an indoor shoot at Stanford during a crowded VR event.</simpara>
<figure role="thumb">
<title>Overheating during livestream</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/heat/overheat-example.png"/>
</imageobject>
<textobject><phrase>overheat example</phrase></textobject>
</mediaobject>
</figure>
<simpara>If the THETA is overheating, point a standard household fan at it. The airflow
may be enough to cool the outside of the THETA and help with the internal
overheating.</simpara>
<simpara>People have reported success by sticking $6 Raspberry Pi heatsinks onto the body of the THETA or
taping or attaching a small fan used for computer CPUs to the outside of the THETA.</simpara>
<figure role="thumb">
<title>Raspberry Pi Heatsinks (L), small computer fan bracket &#174;</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/heat/heatsinks.png"/>
</imageobject>
<textobject><phrase>heatsinks</phrase></textobject>
</mediaobject>
</figure>
<itemizedlist>
<listitem>
<simpara><link xl:href="https://amzn.com/B00LKX618Q">6 piece Addicore heatsink</link> for Raspberry Pi for $5.95</simpara>
</listitem>
<listitem>
<simpara><link xl:href="https://amzn.com/B01GE7Q060">Mudder 8 piece black heatsink cooler for RPi</link> for $6.99</simpara>
</listitem>
<listitem>
<simpara><link xl:href="https://www.tinkercad.com/things/7oICypvba1i-theta-s-cooling-fan-holder">TinkerCad Fan Holder for 3D printing</link></simpara>
</listitem>
</itemizedlist>
<simpara>The enthusiast below created custom cases in plastic through a shop
in Akihabara. He wanted to use metal, but the cost
was too high.</simpara>
<figure role="thumb">
<title>Not recommended, but an example of community enthusiasm</title>
<mediaobject>
<imageobject>
<imagedata fileref="img/livestreaming/heat/case-mod.png"/>
</imageobject>
<textobject><phrase>case mod</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section xml:id="_discuss">
<title>Discuss</title>
<simpara>If you have questions, comments or additions, please post them in the
<link xl:href="http://lists.theta360.guide/t/new-theta-360-video-live-streaming-guide-available/477?u=codetricity">THETA Unofficial Guide Forum</link>.</simpara>
<simpara>If you have a product or service that you&#8217;ve <emphasis>verified works with the THETA</emphasis>,
please join the
<link xl:href="http://theta360.guide/ecosystem/">THETA Developer Ecosystem</link>. Once you&#8217;ve joined the ecosystem, you
can post your product information in the
<link xl:href="http://lists.theta360.guide/c/theta-media/ecosystem-discussion">Ecosystem Discussion</link> category.</simpara>
</section>
<section xml:id="__link_xl_href_http_theta360_guide_return_to_theta360_guide_link">
<title><link xl:href="http://theta360.guide/">Return to theta360.guide</link></title>

</section>
</article>